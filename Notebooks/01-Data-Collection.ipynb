{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "723154f2",
   "metadata": {
    "id": "qa91xncbIxsp"
   },
   "source": [
    "# Importing Libraries ðŸ“˜\n",
    "We will be using Python libraries such as pandas, numpy, matplotlib, seaborn, and scikit-learn for data manipulation, visualization, and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcacbf0a",
   "metadata": {
    "executionInfo": {
     "elapsed": 10004,
     "status": "ok",
     "timestamp": 1731058387801,
     "user": {
      "displayName": "Rajib Roy",
      "userId": "00246005228296582612"
     },
     "user_tz": 300
    },
    "id": "r6keAbPNI2pA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec12bbc",
   "metadata": {
    "id": "6-UFY6pEI7RJ"
   },
   "source": [
    "# Loading the Dataset ðŸ“¥\n",
    "Let's load the dataset and take a quick look at the first few rows to understand its structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37afeaff",
   "metadata": {
    "id": "hoZKA9L9A0bz"
   },
   "source": [
    "### Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a25db4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4996,
     "status": "ok",
     "timestamp": 1730944588060,
     "user": {
      "displayName": "Aravind S S",
      "userId": "05130540382526934217"
     },
     "user_tz": -330
    },
    "id": "Gu5cNnYv8ciE",
    "outputId": "087a20cd-5e49-48cf-bf09-d522fc3de9d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination Directory: data/brllrb/uber-and-lyft-dataset-boston-ma\n",
      "Dataset URL: https://www.kaggle.com/datasets/brllrb/uber-and-lyft-dataset-boston-ma\n",
      "License(s): CC0-1.0\n",
      "Downloading uber-and-lyft-dataset-boston-ma.zip to data/brllrb/uber-and-lyft-dataset-boston-ma\n",
      " 70% 31.0M/44.5M [00:00<00:00, 151MB/s] \n",
      "100% 44.5M/44.5M [00:00<00:00, 137MB/s]\n",
      "User cancelled operation\n",
      "Exception ignored in atexit callback: <bound method TMonitor.exit of <TMonitor(Thread-6, stopped daemon 138226392094272)>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/_monitor.py\", line 44, in exit\n",
      "    self.join()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# Dataset name\n",
    "DATASET_NAME = \"brllrb/uber-and-lyft-dataset-boston-ma\"\n",
    "\n",
    "# Directory to store the dataset\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "# Destination directory for the specific dataset\n",
    "DESTINATION_DIR = f\"{DATA_DIR}/{DATASET_NAME}\"\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "!mkdir -p \"{DESTINATION_DIR}\"\n",
    "\n",
    "# Print the destination directory\n",
    "print(f\"Destination Directory: {DESTINATION_DIR}\")\n",
    "\n",
    "# Download the dataset using the Kaggle API\n",
    "!kaggle datasets download -d \"$DATASET_NAME\" -p \"$DESTINATION_DIR\" --unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b9fa1",
   "metadata": {
    "id": "btxXpWElMp3J"
   },
   "source": [
    "### Loading data into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e19d2",
   "metadata": {
    "id": "tJRNVncsNDFM"
   },
   "source": [
    "### Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6918453d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5294,
     "status": "ok",
     "timestamp": 1731058396678,
     "user": {
      "displayName": "Rajib Roy",
      "userId": "00246005228296582612"
     },
     "user_tz": 300
    },
    "id": "h6Lds8WZFCOh",
    "outputId": "4ef577d6-fd60-4afe-f829-cf36ee66a3d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination Directory: data/ElvisGitau/Uber-Fare-Predict\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1159  100  1159    0     0   3240      0 --:--:-- --:--:-- --:--:--  3246\n",
      "100  162M  100  162M    0     0  34.8M      0  0:00:04  0:00:04 --:--:-- 40.6M\n"
     ]
    }
   ],
   "source": [
    "# Dataset name\n",
    "REPO_ID = \"ElvisGitau/Uber-Fare-Predict\"\n",
    "FILENAME = \"final.csv\"\n",
    "\n",
    "# Directory to store the dataset\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "# Destination directory for the specific dataset\n",
    "DESTINATION_DIR = f\"{DATA_DIR}/{REPO_ID}\"\n",
    "\n",
    "# Final file path\n",
    "DESTINATION_PATH = f\"{DESTINATION_DIR}/{FILENAME}\"\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "!mkdir -p \"{DESTINATION_DIR}\"\n",
    "\n",
    "# Print the destination directory\n",
    "print(f\"Destination Directory: {DESTINATION_DIR}\")\n",
    "\n",
    "# Download the file from Hugging Face using curl\n",
    "!curl -L -o \"{DESTINATION_PATH}\" \"https://huggingface.co/datasets/{REPO_ID}/resolve/main/{FILENAME}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202769f",
   "metadata": {
    "id": "yapZkvyG8CJM"
   },
   "source": [
    "### Loading data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DESTINATION_PATH)\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
